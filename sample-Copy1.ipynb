{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'qid1' 'qid2' 'question1' 'question2' 'is_duplicate']\n",
      "(404290, 6)\n",
      "(404290,)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "df = pd.read_csv(\"/home/julian/Project/code/quora_duplicate_questions.tsv\",delimiter='\\t')\n",
    "\n",
    "names=df.columns.values\n",
    "print(names)\n",
    "print(df.shape)\n",
    "\n",
    "y=df['is_duplicate']\n",
    "print(y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train=y[0:50000]\n",
    "y_test=y[50000:100000]\n",
    "\n",
    "subset=df[0:100000]\n",
    "#df=subset\n",
    "\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training for embedding\n",
    "import gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df['question1'] = df['question1'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "df['question2'] = df['question2'].apply(lambda x: unicode(str(x),\"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 808580/808580 [01:06<00:00, 12123.81it/s]\n"
     ]
    }
   ],
   "source": [
    "questions=list(df['question1'])+list(df['question2'])\n",
    "c=0\n",
    "for i in tqdm(questions):\n",
    "    questions[c]=list(gensim.utils.tokenize(i,deacc=True,lower=True))\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.47635266e-01   2.02503845e-01  -3.00855905e-01   7.04323828e-01\n",
      "   5.16311228e-01   2.34611854e-01  -1.06530595e+00   1.79300085e-01\n",
      "   1.47915792e+00   6.21605814e-01  -5.87303638e-01   3.15053314e-02\n",
      "  -9.59633589e-02  -2.97713894e-02   4.35157001e-01   4.26067531e-01\n",
      "   8.58545125e-01   7.41145194e-01   1.21569800e+00  -4.43062276e-01\n",
      "  -1.55046439e+00   8.58229578e-01   5.79359055e-01   2.00924826e+00\n",
      "  -1.41297615e+00   1.34151936e+00  -4.69542086e-01   5.12131810e-01\n",
      "  -2.29192704e-01   2.45426923e-01  -8.73400986e-01   4.35823709e-01\n",
      "   1.33816898e+00  -8.19411337e-01  -1.21927273e+00   8.05692375e-01\n",
      "  -1.04685938e+00   9.61022913e-01   3.88170153e-01  -6.20268643e-01\n",
      "  -1.81212962e+00  -5.67588925e-01  -1.65157542e-01  -7.19464242e-01\n",
      "  -1.12206340e-01  -1.00563693e+00   1.40891686e-01  -1.09762836e+00\n",
      "   9.72508788e-01  -5.02483964e-01   5.18619239e-01  -8.78886878e-02\n",
      "  -2.75892854e-01  -1.11928016e-01   3.51531915e-02  -1.59858990e+00\n",
      "   9.63451982e-01   1.01817083e+00  -3.62114519e-01   3.97619568e-02\n",
      "  -1.42630768e+00  -7.39161134e-01  -1.63290769e-01  -4.97091740e-01\n",
      "  -1.23397425e-01  -2.27891421e+00   1.05213535e+00  -5.86095154e-01\n",
      "   1.11241937e+00   5.80016315e-01  -1.09771490e+00  -1.20162321e-02\n",
      "   7.15892315e-01   1.10442117e-01  -6.36777461e-01  -6.12920344e-01\n",
      "   1.63330555e+00   5.18509805e-01   8.25070858e-01  -5.88115156e-01\n",
      "   3.05972934e-01   3.24499696e-01  -9.26556408e-01   2.19136160e-02\n",
      "  -1.20969677e+00  -2.14494090e-03   1.07468717e-01  -2.83604234e-01\n",
      "   4.21242386e-01  -9.59445357e-01  -1.00509763e+00   1.32781163e-01\n",
      "   5.03852367e-01   1.90797318e-02   2.82184601e-01   8.48615050e-01\n",
      "   8.90255868e-02   9.19584453e-01  -1.88211501e-01  -4.55830216e-01\n",
      "  -7.59101927e-01  -3.28284055e-02  -1.07058728e+00  -4.36973065e-01\n",
      "   1.77146375e-01   8.76470685e-01   1.27529871e+00  -1.72811612e-01\n",
      "  -5.76958239e-01  -2.28922233e-01  -9.30180922e-02  -9.91264582e-01\n",
      "   1.96657687e-01  -1.28050637e+00  -4.03177828e-01  -5.87631762e-01\n",
      "  -8.42879295e-01  -3.17570090e-01  -1.36925969e-02   6.15656674e-02\n",
      "   8.04227889e-01  -1.74711561e+00   1.80847555e-01  -7.19252881e-03\n",
      "   7.29769945e-01   3.15126866e-01  -9.39837098e-01  -2.35741273e-01\n",
      "  -5.34888387e-01  -8.48915339e-01  -1.46564126e+00  -1.53454554e+00\n",
      "   6.87654257e-01  -4.47107077e-01  -3.63528430e-01   6.44805372e-01\n",
      "  -9.06846344e-01   6.09071195e-01   4.53652918e-01   3.58816296e-01\n",
      "  -3.43585134e-01  -6.05320275e-01   9.69324231e-01   2.54210114e-01\n",
      "  -1.14213848e+00  -1.41873038e+00   2.52733938e-02  -2.39057660e+00\n",
      "   5.45657575e-01  -4.73188281e-01  -1.04430914e+00   1.86719227e+00\n",
      "   1.82972774e-01   1.15993306e-01   1.40891746e-01  -6.22604728e-01\n",
      "   1.03124702e+00   9.07842875e-01  -7.37207770e-01   8.60827804e-01\n",
      "   1.31682742e+00  -1.28424009e-02  -3.58936787e-01  -6.37739062e-01\n",
      "  -4.09134001e-01  -9.45207536e-01   7.42139876e-01  -3.98013383e-01\n",
      "   2.54741251e-01  -1.91636884e+00   1.92743391e-01   1.57103443e+00\n",
      "   5.57665646e-01  -5.99330962e-01   2.99834609e-01  -9.56044257e-01\n",
      "   9.21460271e-01  -1.39492154e+00   3.38219613e-01   5.58641672e-01\n",
      "  -6.99108839e-02  -7.67464221e-01   1.45239604e+00   1.01614702e+00\n",
      "   8.92169252e-02  -1.35512209e+00  -3.14006478e-01  -1.11620307e+00\n",
      "   5.67368805e-01  -1.81018516e-01   1.82800257e+00  -3.18569630e-01\n",
      "   7.79845834e-01  -3.88644546e-01   8.92014742e-01  -8.31390619e-01\n",
      "  -7.61186033e-02  -1.91294849e-01   7.95106664e-02  -1.64285317e-01\n",
      "   1.21038961e+00   9.24885988e-01   3.35010350e-01   9.98107314e-01\n",
      "  -4.92686108e-02   4.68110710e-01   6.07983649e-01  -1.24591184e+00\n",
      "  -1.74376070e-01  -1.28476202e+00   1.81296611e+00  -1.66224074e+00\n",
      "   1.28918576e+00  -1.18671313e-01  -2.82556504e-01  -1.37834445e-01\n",
      "   1.10051978e+00  -1.16666389e+00   6.24611676e-01  -5.80366611e-01\n",
      "  -3.76328006e-02  -9.26960528e-01   8.70693982e-01  -6.66201234e-01\n",
      "   3.96072567e-01   5.97229660e-01  -1.11398005e+00  -9.37655747e-01\n",
      "   9.40638125e-01   4.48252738e-01   1.06150103e+00  -2.50832468e-01\n",
      "   7.72314608e-01   5.21158457e-01   4.84445006e-01  -2.62810569e-02\n",
      "  -5.12222350e-01  -2.01000214e-01  -7.15611100e-01  -2.40663692e-01\n",
      "  -1.50218066e-02   4.28371161e-01   5.36814630e-01  -1.97717202e+00\n",
      "  -4.47878599e-01  -2.23720163e-01   2.86986709e-01   1.18361674e-01\n",
      "  -9.46748257e-03   8.55562389e-01  -6.05947733e-01   5.26917636e-01\n",
      "  -8.79911304e-01  -3.77384543e-01   2.51541704e-01   1.32220781e+00\n",
      "  -3.36055219e-01  -5.44090867e-02   1.86383966e-02   4.48663086e-01\n",
      "   2.14248371e+00  -7.20493376e-01  -1.93560445e+00  -1.82348549e+00\n",
      "   1.16977179e+00  -1.04378831e+00  -5.35268724e-01  -4.29811448e-01\n",
      "  -9.51622486e-01   5.33377051e-01  -9.66999471e-01  -2.52644092e-01\n",
      "   1.39695966e+00  -1.46008706e+00  -4.66157228e-01  -6.64497972e-01\n",
      "   7.69122303e-01  -3.07273924e-01   7.81594872e-01  -9.08481479e-01\n",
      "   1.31148589e+00   5.00638597e-03  -6.04256630e-01   1.53805315e+00\n",
      "  -5.72967589e-01  -4.52964246e-01   4.04288650e-01   7.69230306e-01\n",
      "  -2.91454649e+00   5.83251238e-01  -8.22479248e-01  -6.36433959e-01\n",
      "  -8.83253753e-01   8.87977958e-01   2.18575448e-01   2.67276093e-02\n",
      "   1.93881094e+00   5.08170784e-01  -1.17067111e+00  -9.94272411e-01]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "embed_model=Word2Vec(questions,size=300,min_count=10)\n",
    "print(embed_model['what'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence,text\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout,Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tk=text.Tokenizer(filters=\"\")\n",
    "max_len=40\n",
    "tk.fit_on_texts(list(subset.question1.values)+list(subset.question2.values))\n",
    "x1 = tk.texts_to_sequences(subset.question1.values)\n",
    "x1 = sequence.pad_sequences(x1,maxlen = max_len)\n",
    "\n",
    "x2 = tk.texts_to_sequences(subset.question2.values)\n",
    "x2 = sequence.pad_sequences(x1,maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the step by step guide to invest in share market in india?\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    2    3    1 1464\n",
      "   53 1464 3206    7  514    8  689  602    8   57]\n"
     ]
    }
   ],
   "source": [
    "q=subset['question1']\n",
    "print(q[0])\n",
    "print(x1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92844\n"
     ]
    }
   ],
   "source": [
    "nb_words=len(tk.word_index)+1\n",
    "print(nb_words)\n",
    "#print(subset.question1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-6be6b3defdf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx1_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx1_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx2_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx2_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "x1_train=x1[0:50000]\n",
    "x1_test=x1[50000:100000]\n",
    "x2_train=x2[0:50000]\n",
    "x2_test=x2[50000:100000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 40)\n",
      "(50000, 40)\n",
      "(50000,)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(x1_train.shape)\n",
    "print(x1_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "#y_train=y_train.reshape((1,10))\n",
    "#y_test=y_test.reshape((1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "embedding_matrix = np.zeros((nb_words, 300))\n",
    "\n",
    "for word, i in tk.word_index.items():\n",
    "    embedding_vector = None \n",
    "    if word in embed_model.wv.vocab:\n",
    "        embedding_vector = embed_model[word]\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "#print(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 40, 300)           27853200  \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 100)               160400    \n",
      "=================================================================\n",
      "Total params: 28,013,600\n",
      "Trainable params: 28,013,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vecor_length = 300\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(nb_words, embedding_vecor_length,weights=[embedding_matrix], input_length=max_len))\n",
    "#x1=model1.add(LSTM(100,return_sequences=True))\n",
    "x1=model1.add(LSTM(100))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model1.summary())\n",
    "#model1.fit(x1_train, y_train, validation_data=(x1_test, y_test),epochs=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 40, 300)           27853200  \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 100)               160400    \n",
      "=================================================================\n",
      "Total params: 28,013,600\n",
      "Trainable params: 28,013,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vecor_length = 300\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(nb_words, embedding_vecor_length,weights=[embedding_matrix], input_length=max_len))\n",
    "#x2=model2.add(LSTM(100,return_sequences=True))\n",
    "x2=model2.add(LSTM(100))\n",
    "#model2.add(Dense(1, activation='sigmoid'))\n",
    "#model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model2.summary())\n",
    "#model2.fit(x2_train, y_train, validation_data=(x2_test, y_test),epochs=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julian/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_6 (Merge)              (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 56,057,501\n",
      "Trainable params: 56,057,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 50000 samples, validate on 50000 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 3311s - loss: 0.5660 - acc: 0.7079 - val_loss: 0.5440 - val_acc: 0.7282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2a5831c210>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Merge([model1, model2], mode='concat'))\n",
    "#model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit([x1_train,x2_train],y_train,validation_data=([x1_test,x2_test],y_test),epochs=1,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54395649314880368, 0.72824]\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate([x1_test,x2_test],y_test,verbose=0)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-69308f0a60ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx1_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#x2_test=x2[60000:60100]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#y_test=y[60000:60100]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "x1_test=x1[0:100]\n",
    "#x2_test=x2[60000:60100]\n",
    "#y_test=y[60000:60100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-e1f9e95a7021>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict([x1[100000:100100],x2[100000:100100]],batch_size=2,verbose=0)\n",
    "count=0\n",
    "for i in range(100):\n",
    "    if(y_pred[i]>=0.5):\n",
    "        res=1\n",
    "    else:\n",
    "        res=0\n",
    "    print(res)\n",
    "    print(y_test[50000+i])\n",
    "    if(res==y_test[50000+i]):\n",
    "        count=count+1\n",
    "    print(' ')\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-be11169d988d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/julian/anaconda/lib/python2.7/site-packages/sklearn/metrics/pairwise.pyc\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m    879\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julian/anaconda/lib/python2.7/site-packages/sklearn/metrics/pairwise.pyc\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julian/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    396\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julian/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     52\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     53\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 54\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-66983decbeb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m embedding_layer = Embedding(nb_words,\n\u001b[1;32m      2\u001b[0m                                 \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                 \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                                 \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                 trainable=False)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(nb_words,\n",
    "                                10,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=30,\n",
    "                                trainable=False)\n",
    "print(embedding_layer)\n",
    "lstm_layer = LSTM(75, recurrent_dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH=30\n",
    "sequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=\"int32\")\n",
    "embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
    "x1 = lstm_layer(embedded_sequences_1)\n",
    "\n",
    "sequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=\"int32\")\n",
    "embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
    "y1 = lstm_layer(embedded_sequences_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HIDDEN_DIM=30\n",
    "EMBED_DIM=10\n",
    "seq_maxlen=30\n",
    "ques1_enc = Sequential()\n",
    "ques1_enc.add(Embedding(output_dim=EMBED_DIM, input_dim=nb_words,\n",
    "                       weights=[embedding_matrix], mask_zero=True))\n",
    "ques1_enc.add(LSTM(HIDDEN_DIM, input_shape=(EMBED_DIM, seq_maxlen), \n",
    "                       return_sequences=False))\n",
    "ques1_enc.add(Dropout(0.3))\n",
    "    \n",
    "ques2_enc = Sequential()\n",
    "ques2_enc.add(Embedding(output_dim=EMBED_DIM, input_dim=nb_words,\n",
    "                       weights=[embedding_matrix], mask_zero=True))\n",
    "ques2_enc.add(LSTM(HIDDEN_DIM, input_shape=(EMBED_DIM, seq_maxlen), \n",
    "                       return_sequences=False))\n",
    "ques2_enc.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julian/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Merge([ques1_enc, ques2_enc], mode=\"sum\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "    \n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "        filepath=os.path.join(MODEL_DIR, \"quora_dul_best_lstm.hdf5\"),\n",
    "        verbose=1, save_best_only=True)\n",
    "    model.fit([x_ques1train, x_ques2train], ytrain, batch_size=BATCH_SIZE,\n",
    "              epochs=NBR_EPOCHS, \n",
    "              validation_split=0.1,\n",
    "              verbose=2,\n",
    "              callbacks=[checkpoint])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 1 0 0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The model expects 2 input arrays, but only received one array. Found: array with shape (122, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-6c5c60c80350>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model.fit([data_1, data_2], y_train, batch_size=2,epochs=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/julian/anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/julian/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1523\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julian/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1376\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1379\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1380\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julian/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    109\u001b[0m                              \u001b[0mexception_prefix\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                              \u001b[0;34m' arrays, but only received one array. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                              'Found: array with shape ' + str(data.shape))\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The model expects 2 input arrays, but only received one array. Found: array with shape (122, 10)"
     ]
    }
   ],
   "source": [
    "#model.fit([data_1, data_2], y_train, batch_size=2,epochs=1)\n",
    "print(y_train)\n",
    "model.fit(embedding_matrix,y_train,batch_size=2,epochs=1)  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
