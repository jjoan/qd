{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'qid1' 'qid2' 'question1' 'question2' 'is_duplicate']\n",
      "(404290, 6)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "df = pd.read_csv(\"/home/julian/Project/code/quora_duplicate_questions.tsv\",delimiter='\\t')\n",
    "\n",
    "names=df.columns.values\n",
    "print(names)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training for embedding\n",
    "import gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['question1'] = df['question1'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "df['question2'] = df['question2'].apply(lambda x: unicode(str(x),\"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 808580/808580 [08:56<00:00, 1508.09it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "questions=list(df['question1'])+list(df['question2'])\n",
    "c=0\n",
    "for i in tqdm(questions):\n",
    "    questions[c]=list(gensim.utils.tokenize(i,deacc=True,lower=True))\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model=Word2Vec(questions,size=10,min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=29165, size=10, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1=df['question1']\n",
    "x2=df['question2']\n",
    "y=df['is_duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence,text\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout,Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tk=text.Tokenizer(num_words=200000)\n",
    "max_len=40\n",
    "tk.fit_on_texts(list(df.question1.values)+list(df.question2.values))\n",
    "x1 = tk.texts_to_sequences(df.question1.values)\n",
    "x1 = sequence.pad_sequences(x1,maxlen = max_len)\n",
    "\n",
    "x2 = tk.texts_to_sequences(df.question2.values)\n",
    "x2 = sequence.pad_sequences(x1,maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_words=len(word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m=df.shape[0]\n",
    "train_start = 0\n",
    "train_end = int(.5*m)\n",
    "test_start = int(.5*m)\n",
    "test_end = m\n",
    "\n",
    "x1_train=x1[train_start:train_end]\n",
    "x2_train=x2[train_start:train_end]\n",
    "y_train=y[train_start:train_end]\n",
    "x1_test=x1[test_start:test_end]\n",
    "x2_test=x2[test_start:test_end]\n",
    "y_test=y[test_start:test_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(x1_train.shape)\n",
    "print(x1_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((nb_words, 10))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = None \n",
    "    if word in model.wv.vocab:\n",
    "        embedding_vector = model[word]\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_vecor_length = 10\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(nb_words, embedding_vecor_length,weights=[embedding_matrix], input_length=max_len))\n",
    "x1=model1.add(LSTM(100,return_sequences=True))\n",
    "#model1.add(Dense(1, activation='sigmoid'))\n",
    "#model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_vecor_length = 10\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(nb_words, embedding_vecor_length,weights=[embedding_matrix], input_length=max_len))\n",
    "model2.add(LSTM(100,return_sequences=True))\n",
    "#model2.add(Dense(1, activation='sigmoid'))\n",
    "#model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model2.summary())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
